{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='red'>Stage 3. Face detection by camera </font>"
      ],
      "metadata": {
        "id": "Awy4phzfSlZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "import cv2\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "igWRztEPSmBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained face mask detection model\n",
        "model = load_model('model-020.model')\n",
        "\n",
        "# Open a connection to the webcam\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "# Checking if a camera can be open.\n",
        "if not cap.isOpened():\n",
        "    print(\"Cannot open camera\")\n",
        "    exit()\n",
        "\n",
        "# Import cascade file for facial recognition.\n",
        "face_clsfr = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "\n",
        "# Dictionary to map labels to your friends' names\n",
        "labels_dict = {0: 'Your Face', 1: 'Friend1', 2: 'Friend2', 3: 'Friend3', 4: 'Friend4', 5: 'Friend5'}\n",
        "# Index corresponding to your face\n",
        "your_face_label = 0\n",
        "\n",
        "# Color dictionary for bounding box colors\n",
        "color_dict = {0: (0, 255, 0)}\n",
        "for label in range(1, 6):\n",
        "    color_dict[label] = (0, 0, 255)\n",
        "\n",
        "rect_size = 4\n",
        "\n",
        "# Define the codec and create VideoWriter object.\n",
        "# The output is stored in 'output.avi' file.\n",
        "out = cv2.VideoWriter('output.avi', cv2.VideoWriter_fourcc('M','J','P','G'), 20, (640, 480))\n",
        "\n",
        "# Main loop for capturing video and performing face detection\n",
        "while True:\n",
        "    # Read a frame from the webcam\n",
        "    ret, img = cap.read()\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Detect faces using Haar Cascade Classifier\n",
        "    faces = face_clsfr.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "    # Loop through detected faces\n",
        "    for (x, y, w, h) in faces:\n",
        "        # Extract the face region\n",
        "        face_img = gray[y:y+w, x:x+w]\n",
        "        resized = cv2.resize(face_img, (100, 100))\n",
        "        normalized = resized / 255.0\n",
        "        reshaped = np.reshape(normalized, (1, 100, 100, 1))\n",
        "\n",
        "        # Make predictions using the face mask detection model\n",
        "        result = model.predict(reshaped)\n",
        "        label = np.argmax(result, axis=1)[0]\n",
        "\n",
        "        # Draw bounding box around the face and display label\n",
        "        cv2.rectangle(img, (x, y), (x+w, y+h), color_dict[label], rect_size)\n",
        "        cv2.putText(img, labels_dict[label], (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color_dict[label], 2)\n",
        "\n",
        "    # Display the frame\n",
        "    cv2.imshow('LIVE', img)\n",
        "\n",
        "    # Write the frame to the output video file\n",
        "    out.write(img)\n",
        "\n",
        "    # Check for the 'Esc' key to exit the loop\n",
        "    key = cv2.waitKey(1)\n",
        "    if key == 27:  # ASCII value for Esc key\n",
        "        break\n",
        "\n",
        "# Release the webcam, video writer, and close all windows\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "qy5wfbJhTUTE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "241d5e63-0dbf-4037-b628-65d206828cad"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f9b4488d3c40>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model-020.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Import cascade file for facial recognition.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'load_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ezu9SMCXTaPe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "d561b428-4de9-4e1b-f44a-112890834db0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-889d2b689970>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrect_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
          ]
        }
      ]
    }
  ]
}